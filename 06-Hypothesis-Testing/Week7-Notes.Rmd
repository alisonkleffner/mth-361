---
title: "MTH361: Probability and Statistics in the Health Sciences"
author: "Hypothesis Testing"
date: "March 4, 2025"
output: 
  xaringan::moon_reader:
    lib_dir: libs
    seal: false
    css: ["default", "metropolis-fonts", "modal.css", "sizeformat.css"]
    includes:
      after_body:
        "js-addins.html"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r echo=FALSE, message=FALSE, warning = FALSE}
library(knitr)
library(tidyverse)
library(xaringanthemer)
library(xaringanExtra)

style_duo_accent(primary_color = "#0054a6",
                 secondary_color = "#f1fffe",
  header_font_google = google_font("Source Sans Pro"),
  text_font_google = google_font("Source Sans Pro"))

hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

xaringanExtra::use_tachyons()

xaringanExtra::use_tile_view()
```

```{r, include = F, eval = T, cache = T}
clean_file_name <- function(x) {
  basename(x) %>% str_remove("\\..*?$") %>% str_remove_all("[^[A-z0-9_]]")
}
img_modal <- function(src, alt = "", id = clean_file_name(src), other = "") {
  
  other_arg <- paste0("'", as.character(other), "'") %>%
    paste(names(other), ., sep = "=") %>%
    paste(collapse = " ")
  
  js <- glue::glue("<script>
        /* Get the modal*/
          var modal{id} = document.getElementById('modal{id}');
        /* Get the image and insert it inside the modal - use its 'alt' text as a caption*/
        var img{id} = document.getElementById('img{id}');
          var modalImg{id} = document.getElementById('imgmodal{id}');
          var captionText{id} = document.getElementById('caption{id}');
          img{id}.onclick = function(){{
            modal{id}.style.display = 'block';
            modalImg{id}.src = this.src;
            captionText{id}.innerHTML = this.alt;
          }}
          /* When the user clicks on the modalImg, close it*/
          modalImg{id}.onclick = function() {{
            modal{id}.style.display = 'none';
          }}
</script>")
  
  html <- glue::glue(
     " <!-- Trigger the Modal -->
<img id='img{id}' src='{src}' alt='{alt}' {other_arg}>
<!-- The Modal -->
<div id='modal{id}' class='modal'>
  <!-- Modal Content (The Image) -->
  <img class='modal-content' id='imgmodal{id}'>
  <!-- Modal Caption (Image Text) -->
  <div id='caption{id}' class='modal-caption'></div>
</div>
"
  )
  write(js, file = "js-addins.html", append = T)
  return(html)
}
# Clean the file out at the start of the compilation
write("", file = "js-addins.html")
```

class:inverse

<br><br><br>
## MTH361: Probability and Statistics in the Health Sciences
### Hypothesis Tests
#### March 4, 2025

---
### Announcements

- **Lab 5** in class Thursday March 6
  - due Friday March 7 at 11:59pm in Blueline
  - Data Collection: Play Rock-Paper-Scissors with a friend 12 times and count the number of times they chose scissors (do not tell them what you are counting). Fill out the form: **Lab 5: Rock Paper Scissors Data Collection** by class time on **Thursday March 6**. We will use this data in the lab. 
- **Homework 5**
  - Due Tuesday March 18 at 11:59pm in Blueline
- **Midterm**: Thursday March 20 in class
  - Some review materials in Blueline. Review Day on Tuesday March 18
    + Midterm Question Form

<br>

Book Chapters:

- **Today**: 4.3 and 5.1

---
### From Confidence Intervals to Hypothesis Tests

Recall from the notes last week:

**The data provides evidence that the the BMI of Americans is above the healthy range of BMI ([18.5, 24.9]).**

We also know the 95% confidence interval is [25.46, 27.74].

Today we are going to discuss and solve these kind of question in a Hypothesis way: Given a sample, how to make conclusion about the population statistics.

---
### Hypothesis Testing

**Disclaimer:** Lots of people have strong feelings about hypothesis testing

```{r, echo=FALSE, fig.align='center', out.height="60%", out.width="60%"}
knitr::include_graphics("../06-Hypothesis-Testing/images/pvalue-controversy.png")
```

---
### Hypothesis Testing

Hypothesis tests are designed to answer a yes/no research question: if have a set of two competing hypotheses, which one is more plausible given the data we've observed?

- Despite the recent controversy, hypothesis testing is still the most used class of statistical procedures in the sciences
- There are lots of variations of hypothesis tests, depending on the data we are interested in. The basic structure and thought process remains the same.


---
### Hypothesis Testing

Hypothesis testing is a method for evaluating the evidence for/against a specific research claim based on a probability, called a p-value. There are four basic steps to this procedure:

1. Write the null and alternative hypothesis
2. Collect evidence from our sample and calculate a test statistic
3. “Translate” the test statistic into a p-value
4. Make a conclusion based on the p-value

---
### Step 1: Write Hypotheses

If you want to study something, you need an assumption/expectation/guess for your result $\longrightarrow$ Hypothesis

A Hypothesis contains two mutually exclusive parts:

- Null Hypothesis
- Alternative Hypothesis

Goal: We want to show that our data indicates the probability of null hypothesis happens is quite low (nearly impossible to happen), thus, the alternative hypothesis is more likely to be true.

---
### Step 1: Write Hypotheses

Null Hypothesis $(H_0)$: The null hypothesis represents an assumption or a skeptical statement about the population parameter, and always includes just a single value.
  
  - "Random Chance Alone"

Alternative Hypothesis $(H_A)$: A competing hypothesis contrasts to the null hypothesis, usually is what the original research question hoped to show, prove, or find evidence for.

  - "There is an effect"

Note: Alternative hypothesis can be one-sided ("increased", "decreased") or two-sided ("changed", "different").

---
### Step 1: Write Hypotheses

**Example**: Drug maker GlaxoSmithKline (GSK) investigated the potential impact of its oral anti-diabetic drug Avandia on the blood lipid levels of adult diabetics who might benefit from taking Avandia. They were particularly concerned that LDL, "bad" cholesterol, levels might increase. Write the null and alternative hypothesis for their test.


---
### Step 2: Calculate the Test Statistic 

Given the hypothesis, now we need to use data to show whether the hypothesis is valid or not, through test statistics. 

- Test statistic: a number calculated from the sample data that is used to evaluate how far the data we've observed are from the result expected assuming the null hypothesis is true.

Usually the test statistic follows this form:

$$\text{test statistic} = \frac{\text{sample statistic} - \text{expectation}}{\text{standard error}}$$
As we'll see, the choice of test statistic depends on two things

- The type of data we're analyzing
- The assumptions we're willing to make

---
### Step 3: Calculate the p-value

It's useful to translate the test statistic into another measurement that's consistent for all types of hypothesis tests. 

p-value: the **probability** of observing a sample statistic as or more extreme as the sample statistic we have observed, assuming the null hypothesis is true.

**The p-value is not the probability that the null hypothesis is true!**

```{r, echo=FALSE, fig.align='center', out.height="80%", out.width="80%"}
knitr::include_graphics("../06-Hypothesis-Testing/images/pvalue-def.png")
```

---
### Step 3: Assuming Null Hypothesis is True?

Assuming Randomness!

Do you remember the Arson Activity from the first day of class?

```{r, echo=FALSE, fig.align='center', out.height="70%", out.width="70%"}

```

You didn't know it at the time, but we created a Null Distribution!
---
### Step 3: Calculate the p-value

Student t distribution:

- The t-distribution has a symmetric smooth shape.
- The normal distribution assumes $\sigma$ is known. The t-distribution does not.
- The t-distribution is defined by the degrees of freedom. These are related to the sample size.
- As the sample size increases, the t-distribution becomes more similar to the normal distribution.


```{r, echo=FALSE, out.width="50%", fig.align='center'}

knitr::include_graphics("../06-Hypothesis-Testing/images/t-distribution.png")

```

---
### Step 4: Make a conclusion

- If the p-value is ”small”, we **reject** the null hypothesis. Assuming the null hypothesis is true, the probability of observing a sample statistic as or more extreme as ours is very low. There are two explanations:
  + Our sample data is extremely unusual or unlikely, and the null hypothesis is still true.
  + Our sample data is typical, and the null hypothesis is not plausible.
  
- If the p-value is ”large”, we **fail to reject** the null hypothesis. 
  + This doesn’t imply that the null hypothesis is true! It does imply that the data we observed is consistent with what would happen IF the null hypothesis were true.

---
### Step 4: Make a conclusion


How ”small” is small? How ”large” is large?

Significance level: a predetermined value that we compare the p-value to

- If the p-value is < $\alpha$, we will reject the null hypothesis. 
  + We have ”strong enough” evidence to conclude the null hypothesis is false.
- If the p-value is > $\alpha$, we will fail to reject the null hypothesis. 
  + We do not have enough evidence to reject the null hypothesis.
  
**Note**: Significance level = 1 - Confidence Level

Does not mean we know the population value.

Most disciplines will use $\alpha$ = 0.05 by default, and that a p-value must be
below 0.05 to be **“statistically significant”**.

[More on p-values](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5187603/)

---
### P-values are controversal

No statistical reason for choosing $\alpha$ = 0.05

```{r, echo=FALSE, out.width="35%", out.width="35%", fig.align='center'}

knitr::include_graphics("../06-Hypothesis-Testing/images/pvalue-controversy2.png")

```

Must define $\alpha$ before test!

---
### P-values are controversal

Statistical vs Practical Significance:

- Statistical significance shows that an effect exists in a study, practical significance shows that the effect is large enough to be meaningful in the real world

Hypothesis tests with small effect sizes can produce very low p-values if you have large sample size or the data have low variability. 
  - Hence, effect sizes that are trivial in the practical sense can be highly statistically significant.
  - Note: Effect size measures the strength of the relationship between two variables in a population
  
---
### Example: Insomia

.bg-washed-blue.b--blue.ba.ph3[

__Example__: Belsomra is a drug prescribed for insomnia. A randomized, placebo-controlled clinical trial found that patients assigned to take Belsomra for three months fell asleep 35 minutes faster, on average, than they did before the study -- a statistically significant improvement.

- Would you consider an __effect size__ of falling asleep 35 minutes sooner important in the context of patients suffering from insomnia? Explain why or why not.

]


---
### Example: Insomia

.bg-washed-blue.b--blue.ba.ph3[

__Example__: By contrast, patients assigned to take a placebo for three months fell asleep 27 minutes faster than they did originally -- also statistically significant. The difference between taking Belsomra and taking a placebo was, on average falling asleep 8 minutes faster with Belsomra.

- Would you consider an **effect size** of 8 minutes important in the context of patients suffering from insomnia? 
- Explain why this result occurred.]


---
### Step 4: Make a conclusion

Usually the decision can be a little more complicated:

- How strong is the evidence from the p-value?
- How trustworthy is the sample?
- What are the consequences of being wrong?


When you’re summarizing the results of any hypothesis test, three things should always be included.

- The decision (reject $H_0$ or fail to reject $H_0$).
- The rationale for the decision (test statistic and p-value, most researchers will parenthesize these or put them in a table).
- An interpretation of the decision in context. What are the practical implications? How can you answer the research question based on this hypothesis test?

---
### Focus: One-Sample T-Test

Right now, we are focusing on the type of hypothesis called: One-Sample T-Test

- Asking if the measurements of a sample are consistent with some hypothesized value for the population **mean**. 


So our test statistic...

$$\text{test statistic} = \frac{\text{sample statistic} - \text{expectation}}{\text{standard error}} \longrightarrow t =  \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}$$

---
### Example: BMI

A BMI in adults of 25.0 or greater is considered overweight. Based on the data from the NHANES sample, is there strong enough evidence to show that the population mean BMI for American adults is greater than 25.0?

Write the null and alternative hypothesis, and calculate the test statistic.

```{r, echo = FALSE}
library(NHANES)
library(mosaic)
library(oibiostat)

data("nhanes.samp")
favstats(~BMI, data=nhanes.samp)
```


---
### Example: BMI 

Identify the p-value, and write a conclusion for the test.

```{r, echo=TRUE}
t.test(~BMI, 
       mu=25, 
       alternative='greater', 
       data=nhanes.samp)
```

---

### Example: Communicating Online
A study suggests that the average college student spends 13 hours per week communicating with others online. You believe that this is an underestimate and decide to collect your own sample for a hypothesis test. You randomly sample 60 students from your dorm and find that on average they spent 13.5 hours a week communicating with others online, with a standard deviation of 1.25 hours.

Write the null and alternative hypothesis, and calculate the test statistic.


```{r, echo=FALSE}
set.seed(361)
online_data <- tibble(online_hours = rnorm(n=60, mean=13.3, sd=1.21))
favstats(~online_hours, data=online_data)
```

---
### Example:  Communicating Online

Identify the p-value, and write a conclusion for the test.

```{r, echo=TRUE}
t.test(~online_hours, 
       mu=13, 
       alternative='greater', 
       data=online_data)
```


---
### Types of Errors

There are four possible outcomes in every hypothesis test. Two outcomes result in a "correct decision"... but the other two outcomes result in an "error".

.bg-washed-yellow.b--yellow.ba.ph3[
__Type 1 Error__: Rejecting the null hypothesis when it is actually true

__Type 2 Error__: Failing to reject the null hypothesis when it is actually false
]


```{r, echo=FALSE, fig.align='center'}

knitr::include_graphics("../06-Hypothesis-Testing/images/error-table.png")

```



---
### Errors and Significance Level

In this context, we can think of the significance level $(\alpha)$ as the probability of rejecting the null hypothesis if it were true. That is the probability of making a Type I Error or a false positive.

.pull-left[
Let's assume $\alpha = 0.10$

- This means, if the null is true, 10% of random samples would produce a sample proportion/mean extreme enough to reject the null hypothesis
- In other words, 10% of the time we reject a true null.
- Problem! We just made the wrong decision 10% of the time!
- What type of error was this?
].pull-right[
```{r, echo=FALSE, fig.align='center', out.height="80%", out.width="80%"}

knitr::include_graphics("../06-Hypothesis-Testing/images/rg-error.png")

```
]



---
### Example: Fibromyalgia

.bg-washed-blue.b--blue.ba.ph3[
A patient was diagnosed with fibromyalgia, a long-term syndrome of body pain, and was prescribed anti-depressants. Being a skeptic, the patient didn’t initially believe that anti-depressants would help her symptoms. However, after a couple months she decides the anti-depressants must be working, because she feels like her symptoms are getting better.
]


---

### Example: Aspirin Active Ingredient

.bg-washed-blue.b--blue.ba.ph3[
__Example__: A pharmaceutical company manufactures aspirin tablets that are sold with the label "active ingredient: aspirin 325 mg". A random sample of 100 aspirin tablets had $\bar{x}=326.9$ mg and $s=3.1$ mg.
]

- What are the consequences of Type 1 and Type 2 errors in this scenario? 
- Which is "worse"?

---

### Adjusting for errors

- We can never prevent these errors but we can take steps to control them! For example, we can set the significance level $\alpha$ to be very small if we'd like to control for Type 1 Error.


- The probability of a Type 2 Error can be controlled by choosing a statistical method with high power. 


.bg-washed-yellow.b--yellow.ba.ph3[
__Power__: probability that a random sample taken from a population will lead to a correct rejection of a false null hypothesis

.center[Power = 1 - Type 2 Error]
]

- A test with high power will have a low probability of a Type 2 Error. Eg: a
test with large sample size.

---

### Adjusting for errors: Trade - Off

Caution! There is a trade-off!!

- As the probability of a Type I Error goes down, the probability of a Type II Error goes up.

```{r, echo=FALSE, fig.align='center', out.height="90%", out.width="90%"}

knitr::include_graphics("../06-Hypothesis-Testing/images/power-table.png")

```



















