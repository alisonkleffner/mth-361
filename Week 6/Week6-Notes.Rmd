---
title: "MTH361: Probability and Statistics in the Health Sciences"
author: "Sampling Distribution and CLT"
date: "September 24, 2024"
output: 
  xaringan::moon_reader:
    lib_dir: libs
    seal: false
    css: ["default", "metropolis-fonts", "modal.css", "sizeformat.css"]
    includes:
      after_body:
        "js-addins.html"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
---

```{r echo=FALSE, message=FALSE, warning = FALSE}
library(knitr)
library(tidyverse)
library(mosaic)

hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

```

```{r, include = F, eval = T, cache = T}
clean_file_name <- function(x) {
  basename(x) %>% str_remove("\\..*?$") %>% str_remove_all("[^[A-z0-9_]]")
}
img_modal <- function(src, alt = "", id = clean_file_name(src), other = "") {
  
  other_arg <- paste0("'", as.character(other), "'") %>%
    paste(names(other), ., sep = "=") %>%
    paste(collapse = " ")
  
  js <- glue::glue("<script>
        /* Get the modal*/
          var modal{id} = document.getElementById('modal{id}');
        /* Get the image and insert it inside the modal - use its 'alt' text as a caption*/
        var img{id} = document.getElementById('img{id}');
          var modalImg{id} = document.getElementById('imgmodal{id}');
          var captionText{id} = document.getElementById('caption{id}');
          img{id}.onclick = function(){{
            modal{id}.style.display = 'block';
            modalImg{id}.src = this.src;
            captionText{id}.innerHTML = this.alt;
          }}
          /* When the user clicks on the modalImg, close it*/
          modalImg{id}.onclick = function() {{
            modal{id}.style.display = 'none';
          }}
</script>")
  
  html <- glue::glue(
     " <!-- Trigger the Modal -->
<img id='img{id}' src='{src}' alt='{alt}' {other_arg}>
<!-- The Modal -->
<div id='modal{id}' class='modal'>
  <!-- Modal Content (The Image) -->
  <img class='modal-content' id='imgmodal{id}'>
  <!-- Modal Caption (Image Text) -->
  <div id='caption{id}' class='modal-caption'></div>
</div>
"
  )
  write(js, file = "js-addins.html", append = T)
  return(html)
}
# Clean the file out at the start of the compilation
write("", file = "js-addins.html")
```

class:inverse

<br><br><br>
## MTH361: Probability and Statistics in the Health Sciences
### Sampling Distribution and CLT
#### September 21, 2024

---
### Announcements

- **Lab 4** in class Thursday September 26
  - due Friday September 27 at 11:59pm in Blueline
  - Will cover material about the Normal Distribution and class today on Sampling Distributions
- **Homework 4**
  - due Thursday October 3 at 11:59pm in Blueline

<br>

Book Chapters:

- **Today**: Section 4.1 and 4.2

- **Next Week**: 4.3 and 5.1
---
### Review on Population and Sample

- We have discussed the concept of population and sample.
- In the "real world" we won't have access to the population data.
- A good sample should be able to represent the population's characteristics
- Today we are going to answer the question on how to use the samples to understand the population

---
### Estimating Population Parameters

**Example**: The Centers for Disease Control (CDC) uses survey data to estimate features of health from samples of the US population. These surveys include:

- National Health Interview Survey (NHIS)
- National Health and Nutrition Examination Survey (NHANES)
- Behavioral Risk Factor Surveillance System (BRFSS)
- The data set *cdc* contains a small number of variables from a random sample of 20,000 BRFSS responses from the year 2000. 

```{r, echo=FALSE}
cdc <- read.csv("../Week 6/data/cdc.csv")
head(cdc)
```


---
### Sample Statistics

- Suppose we pretend that the *cdc* data set represents the entire population of American adults
- Now we randomly select 60 rows from the 20,000 responses as our sample.

```{r, echo=FALSE}

set.seed(4)
cdc_sample <- sample_n(cdc, 60)          
head(cdc_sample) 

```

- A natural way to estimate the population parameter is to calculate the corresponding **sample statistic**
  + Population mean $(\mu)$ $\longrightarrow$ sample mean $(\bar{x})$
  + Population standard deviation $(\sigma)$ $\longrightarrow$ sample standard deviation $s$
  
But we have a problem, samples aren't perfect!

---
### Variability in Estimates

Suppose we want to study the weight variable

.pull-left[
Here is the population mean $\mu$ = 

```{r, echo=FALSE}
mean(cdc$weight)
```
].pull-right[
Here is the sample mean $\bar{x}$ = 
```{r, echo=FALSE}
mean(cdc_sample$weight)
```
]


Close! But not exactly right! How could we get a more accurate sample?


<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

**Note**: The sample mean is also called a **point estimate**
---
### Variability in Estimates

What if the sample size is fixed, but we can take multiple samples? Other random samples of 60 from the population may produce different $\bar{x}$ values.

Means of two more random samples of size 60:

```{r, echo=FALSE}

set.seed(44)
cdc_sample <- sample_n(cdc, 60)          
mean(cdc_sample$weight)

set.seed(444)
cdc_sample <- sample_n(cdc, 60)          
mean(cdc_sample$weight)

```


---
### Variability in Estimates

What are the takeaway points?

- Random samples tend to, most of the time, produce sample statistics that are reasonably close to the population parameter.
- Some samples are "unlucky": they may overestimate or underestimate the population parameter 
  + There aren't very many of these!
- The distribution of sample statistics (which has a very special name) has a symmetric, bell-shaped curve appearance.

---
### Sampling Distribution

**Sampling Distribution**: the probability distribution of all possible values of a sample statistics

- Every statistic has a sampling distribution, but we'll focus on $\bar{x}$ and $\hat{p}$ in this class.
  + Quantitative response: mean $(\bar{x})$
  + Categorical response: proportion $(\hat{p})$
- To describe a sampling distribution, we'll need to know three things:
  - Center (mean)
  - Variation (standard error)
  - Shape

  
.center[
```{r, echo=FALSE, results='asis'}
i2 <- img_modal(src = "../Week 6/images/sampling-distribution.png", alt = "Example of a Sampling Distribution",other=list(width="65%"))

c(str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()


```
]
---
### Standard Error

**Standard Error**: a measure of the **sample-to-sample variability** of the sample statistic.

How far away we expect a "typical" sample statistic to be from the true population parameter. Standard error is the standard deviation of the sample distribution.



**Recall**: What is standard deviation?



The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean



.center[
```{r, echo=FALSE, results='asis'}
i2 <- img_modal(src = "../Week 6/images/sd-vs-se.png", alt = "Standard Deviation vs Standard Error",other=list(width="50%"))

c(str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()


```
]


---
### Standard Error

Sampling Distributions provide the theoretical basis for statistical inference: learning about a population based on a sample.

The sampling distribution of $\bar{x}$ has:

- Mean $(\mu)$
- Standard Error $(SE_{\bar{x}})$ = $\frac{s}{\sqrt{n}}$
  + $s$ is the sample standard deviation
- Shape: approximately normally distributed, as long as the sample size is "large enough"


<br>
<br>
**This is true even if the random variable does not follow a normal distribution.**
<br>
<br>
[Sampling Distribution Animation](https://onlinestatbook.com/stat_sim/sampling_dist/)

---
### Calculating Standard Error

Summary Statistics from our initial sample:

```{r, echo=FALSE}
set.seed(4)
cdc_sample <- sample_n(cdc, 60)
favstats(cdc_sample$weight)
```


---
### Statistical Inference

- Can we find a reasonable estimate or set of estimates for our population parameter?
  + ie. Given a sample, instead of providing a point estimate to the population parameter, we can give a range of value based on the level of confidence we want.
  
- Has our population parameter increased/decreased/changed compared to some other value?
  + ie. What if my sample sizes increases, how will the other values change
  
---
### Confidence Intervals

**Confidence Intervals**: a range of the most plausible or believable values for the population parameter, based on a sample of data. General formula:  
<br>

$$\text{sample statistic} \pm \text{margin of error}$$

<br>
The margin of error (MOE) reflects how uncertain we are about the accuracy of our original sample statistic. 
  - How much "wiggle room" do we want to add?
  
<br>


Large MOE $\longrightarrow$ wide confidence interval $\longrightarrow$ more confidence that the true estimate will be in the interval

Small MOE $\longrightarrow$ narrow confidence interval $\longrightarrow$ less confidence that the true estimate will be in the interval

---
### Confidence Intervals for $\mu$

Suppose weâ€™re interested in estimating the population mean, $\mu$. Based on the sampling distribution, we know that, as long as our sample size is "large enough", we will have

$$\mu - 1.96 \cdot SE_{\bar{x}} < \bar{x} < \mu + 1.96 \cdot SE_{\bar{x}}$$

With a bit of algebra, we get an approximate 95% confidence interval for the mean is:

$$\bar{x} \pm 1.96 \cdot SE_{\bar{x}}$$
---
### Interpretation of a Confidence Interval

Correct Interpretation of a 95% confidence interval:

- If repeated samples were taken, 95% of intervals calculated from those samples will contain the true population mean
- We are 95% confident that the population mean is in the interval

Wrong Interpretation of a 95% confidence interval:

- There is a 95% chance that the true population mean lies within the confidence interval
- 95% of the data will fall into the interval
- If we take another sample, there is a 95% chance the sample mean will be in the interval

---
### Application: CDC

We know that in the CDC data set, the overall mean population weight is $\mu$ = 169.683. Let's pretend we don't know this value (which we usually don't). How often will a confidence interval contain this value?

```{r, echo=FALSE, fig.align='center', fig.height=6, fig.width=10}
set.seed(240)
n <- 100
num_trials <- 100
cdc_means <- 1:num_trials %>%
  map_dfr(~ cdc %>%
            slice_sample(n = n) %>%
            summarize(mean_weight = mean(weight), sd_weight = sd(weight))) %>% mutate(n = n)


cdc_means2 <- cdc_means %>%
  mutate(
    se = sd_weight/sqrt(n),
    ci_lower = mean_weight - 2 * se, # approximately 95% of observations 
    ci_upper = mean_weight + 2 * se,  # are within two standard errors
    sample = 1:100,
    group = ifelse(169.67 <= ci_upper & 169.6 >= ci_lower, "1", "2")
  )

pd <- position_dodge(0.78)

ggplot(cdc_means2, aes(x=sample, y = mean_weight)) +
  #draws the means
  geom_point(position=pd) +
  #draws the CI error bars
  geom_errorbar(data=cdc_means2, aes(ymin=ci_lower, ymax=ci_upper, color = group), width=.1, position=pd) + geom_hline(yintercept = 169.383, linetype = "dashed") + ylab("Confidence Interval")
```



---
### Let's Calculate a Confidence Interval!

Reminder, for our sample: 
  - $\bar{x}$ = 171.4833
  - $s$ = 39.7942
  - $n$ = 60


---
### Let's Interpret the Interval!

Interpret the confidence interval you calculated on the previous slide for the mean population weight of US Adults


---
### Application : BMI

Example: Body mass index (BMI) is one measure of body weight that adjusts for height. The national Health and Nutrition Examination Survey (NHANES) consists of a set of surveys and measurements conducted by the CDC to assess the health and nutritional status of adults and children in the US. Following is summary statistics of BMI of a random sample of 200 individuals from 2009-2010 and 2012-2013. Calculate and interpret a 95% confidence interval for adult BMI.

```{r, echo=FALSE}
x <- data.frame(min = 13.1, Q1 = 20.9, median = 26, Q3 = 30.7, max = 69, mean = 26.6, sd = 8, n = 190, missing = 10)
kableExtra::kable(x)
```

---
### Application : BMI

If the a healthy range of BMI is [18.5, 24.9], does this suggest that Americans tend to be overweight?


---
### Application : BMI

We can also think about this problem using probability: recall $\bar{x} \sim N(\mu, SE_{\bar{x}})$


What is the probability that the difference between the true mean and sample mean is within 0.5 units?


---
### Changing the Confidence Level

$$\bar{x} \pm 1.96 \cdot SE_{\bar{x}}$$

Why 1.96?

<br>
<br>
What if we want to have a different confidence level - say 90%?
- For a 90% confidence level, use z = 1.645
- For a 99% confidence level, use z = 2.58
- For any other confidence level, use the standard normal distribution to find z directly.




---
### Changing the Confidence Level

```{r, echo=FALSE, warning=FALSE, fig.align='center', fig.height=7, fig.width=10}
set.seed(240)
n <- 100
num_trials <- 10
cdc_means <- 1:num_trials %>%
  map_dfr(~ cdc %>%
            slice_sample(n = n) %>%
            summarize(mean_weight = mean(weight), sd_weight = sd(weight))) %>% mutate(n = n)


cdc_means1 <- cdc_means %>%
  mutate(
    se = sd_weight/sqrt(n),
    ci_lower = mean_weight - 1.96 * se, # approximately 95% of observations 
    ci_upper = mean_weight + 1.96 * se,  # are within two standard errors
    sample = 1:10,
    ci = "95%",
    group = ifelse(169.383 <= ci_upper & 169.383 >= ci_lower, "1", "2")
  )

cdc_means2 <- cdc_means %>%
  mutate(
    se = sd_weight/sqrt(n),
    ci_lower = mean_weight - 1.645 * se, # approximately 95% of observations 
    ci_upper = mean_weight + 1.645 * se,  # are within two standard errors
    sample = 0.9:9.9,
    ci = "90%",
    group = ifelse(169.383 <= ci_upper & 169.383 >= ci_lower, "1", "2")
  )

cdc_means3 <- cdc_means %>%
  mutate(
    se = sd_weight/sqrt(n),
    ci_lower = mean_weight - 2.58 * se, # approximately 95% of observations 
    ci_upper = mean_weight + 2.58 * se,  # are within two standard errors
    sample = 1.1:10.1,
    ci = "99%",
    group = ifelse(169.383 <= ci_upper & 169.383 >= ci_lower, "1", "2")
  )

cdc_means_new <- rbind(cdc_means1, cdc_means2, cdc_means3)

pd <- position_dodge(0.78)

ggplot(cdc_means_new, aes(x=sample, y = mean_weight, group = c(ci))) +
  #draws the means
  geom_point(position=pd) +
  labs(y = "Confidence Interval") + 
  geom_errorbar(data=cdc_means_new, aes(ymin=ci_lower, ymax=ci_upper, color = group), width=.1) + geom_hline(yintercept = 169.383, linetype = "dashed")

```

---
### Central Limit Theorem (CLT)

What if we have an infinite number of samples?

sample $\longrightarrow$ population and $s$ $\longrightarrow$ $\sigma$

**Central Limit Theorem (CLT)**: If $X_{1},...,X_{n}$ are $n$ random samples drawn from a population with mean $\mu$ and finite standard deviation $\sigma$. When the sample size is going to infinity, we have $\frac{\bar{x}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$

---
### Use CLT to find the Sample Size

- In Chapter 1, we have discussed how to collect sample data
- However, we did not talk about how large the data has to be
- First, CLT requires the sample size to be large enough
  - Generally, at least 30
- Sample size is decided by the Margin of Error you are willing to have and the population standard deviation.
- Larger samples lead to better confidence intervals, but we also need to consider the practical reasons, like the cost.

---
### Use CLT to find the Sample Size

Recall the BMI application, suppose the population standard deviation is also 8. If I want the the difference between the sample mean and the population mean to be less than 0.5 with probability .95, how many people do I need to sample?



---
### Application: Study Time

You want to update the University study time survey for 2021. The 2014 survey results were: $\bar{x}$ = 20.1 and $s$ = 3.0. Use the 2014 results to estimate the sample size necessary for MOE of 0.25 hours with 95% confidence.

